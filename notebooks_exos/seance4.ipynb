{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests d'adéquation et d'indépendance\n",
    "\n",
    "## Table des matières\n",
    "\n",
    "* [Introduction](#Introduction)\n",
    "* [Tests d'adéquation](#Tests-d'adéquation)\n",
    "* [Test d'indépendance](#Test-d'indépendance)\n",
    "* [Démonstration avec python](#Démonstration-avec-python)\n",
    "* [Tests d'adéquation et d'indépendance avec R](Tests%20d'adéquation%20et%20d'indépendance%20avec%20R.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "À la séance précédente, nous avons vu comment tester l'équivalence entre les moyennes ou les variances de deux populations à partir d'échantillons de celles-ci. Pour pouvoir réaliser ces tests, les populations doivent suivre des lois normales et les populations doivent être indépendantes. Si ces hypothèses n'étaient pas vérifiées, on ne pouvait pas les appliquer.\n",
    "\n",
    "Dans cette séance, nous allons voir comment tester, à partir d'un échantillon, qu'une population suit une loi de probabilité donnée. Nous verrons également que l'on peut tester l'indépendance entre deux variables aléatoires.\n",
    "\n",
    "[Retour en haut](#Table-des-matières)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests d'adéquation\n",
    "\n",
    "Considérons un échantillon aléatoire $(X_1, \\dots, X_n)$ dont on ne connait pas la loi parente. L'objectif est de chercher, parmi les lois usuelles, celle qui «ressemble le plus» à la distribution de notre échantillon.\n",
    "\n",
    "Pour quantifier la notion de ressemblance, nous allons calculer la **fonction de répartition** (f.r.) **empirique** $F_n$ de l'échantillon et la comparer à la f.r. théorique $F$ de la loi retenue. Notre hypothèse nulle sera que l'échantillon suit la loi retenue. Plus précisément, on dira que l'échantillon suit la loi théorique si la distance entre les deux f.r. est inférieure à un seuil $C$. Comme le choix de ce seuil semble arbitraire et difficile à définir, nous allons plutôt fixer la probabilité que la distance soit plus grande que le seuil (erreur de première espèce $\\alpha$). On a donc,\n",
    "$$\n",
    "\\alpha = P\\left\\{ d(F, F_n) > C~\\vert~H_0\\text{ est vraie} \\right\\}.  \n",
    "$$\n",
    "La valeur de $C$ correspondante est appelée **seuil d'acceptation** ou **seuil critique**.\n",
    "\n",
    "<span style=\"color:red\"> La différence entre les différents tests réside dans le choix de la distance $d$. </span>\n",
    "\n",
    "### Test de Kolmogorov-Smirnov\n",
    "\n",
    "Le test de Kolmogorov-Smirnov est non paramètrique. La distance retenue est\n",
    "$$\n",
    " d(F_n, F) = \\sup_{x\\in \\mathbb{R}} \\vert F_n(x) - F(x) \\vert\n",
    "$$\n",
    "que l'on comparera au seuil critique $K_n$ tabulé spécialement pour ce test dans [la table de Kolmogorov-Smirnov](https://moodle.umons.ac.be/pluginfile.php/335048/mod_folder/content/0/Table%20Kolmogorov.pdf?forcedownload=1). La valeur $K_n$ est donnée en fonction de $n$ et de l'erreur de première espèce $\\alpha$.\n",
    "\n",
    "L'échantillon suit la loi retenue si $d(F_n, F) < K_n$.\n",
    "\n",
    "En pratique, pour calculer cette distance, on considère l'échantillon ordonné c'est à dire\n",
    "$$\n",
    "x_{(1)} < x_{(2)} < \\dots < x_{(n)}.   \n",
    "$$\n",
    "La fonction de répartition empirique $F_n$ est alors simplement\n",
    "$$\n",
    "F_n(x) \\equiv P_n\\left\\{X \\in ]-\\infty, x] \\right\\} = \\sum_{x_{(i)} \\leq x} \\dfrac{1}{n}\n",
    "$$\n",
    "\n",
    "### Test du $\\chi^2$\n",
    "\n",
    "Ces test est également non-paramètrique. Considérons un échantillon de taille $n$ et notons, pour l'échantillon, $N_i$ le nombre d'observations $x_i$ ou appartenant à un intervalle $I_i$.\n",
    "\n",
    "Si on note $p_i$, la probabilité théorique de faire l'observation $x_i$ ou d'appartenir à l'intervalle $I_i$. Nous pouvons comparer $N_i$ à l'effectif théorique $n \\cdot p_i$.\n",
    "\n",
    "La distance retenue est,\n",
    "$$\n",
    "d(F_n, F) = \\sum_{i=1}^{k} \\dfrac{(N_i - n p_i)^2}{n p_i}\n",
    "$$\n",
    "où $k$ est le nombre d'intervalles ou de valeurs.\n",
    "Dans la limite où $n\\rightarrow +\\infty$, $N_i\\sim\\mathcal{N}(n p_i, n p_i (1-p_i))$ et donc $d \\sim \\chi^2_{k-1}$. Le **seuil critique** </span> $C$ est, dans ce cas, le **fractile d'ordre $1-\\alpha$ de la loi du khi-deux à $k-1$ d.d.l**. En pratique, on approximera $d \\sim \\chi^2_{k-1}$ si $n p_i > 5$. Si ce n'est pas le cas, on regroupera des valeurs (ou intervalles) contiguës.\n",
    "\n",
    "Il est souvent plus facile de calculer la distance à l'aide de la formule développée\n",
    "\n",
    "$$\n",
    " d(F_n, F) = \\left( \\sum_{i=1}^{k} \\dfrac{N_i^2}{n p_i} \\right) - n.\n",
    "$$\n",
    "\n",
    "L'échantillon suit la loi retenue si $d(F_n, F) < \\chi^2_{k-1; 1-\\alpha}$.\n",
    "\n",
    "<span style=\"color:red\"> Si la loi retenue dépend de paramètres que l'on doit estimer, il faudra utiliser $\\chi^2_{k-1-r; 1-\\alpha}$ où $r$ est le nombre de paramètres à estimer. </span>\n",
    "\n",
    "### Remarques\n",
    "\n",
    "Nous avons vu deux tests pour vérifier l'adéquation de la distribution de notre échantillon à une loi de probabilité donnée. On peut donc se demander lequel choisir. Il n'y a pas une règle universelle et les deux tests peuvent être utilisés dans toutes les situations puisqu'il n'y a pas de restriction sur la loi théorique retenue. Cependant, pour appliquer le test du $\\chi^2$ pour une loi continue, il faut considérer différents intervalles alors que le test de Kolmogorov-Smirnov ne s'appuie que sur la fonction de partition.\n",
    "1. Si la loi retenue est discrète, on peut facilement appliquer le test du $\\chi^2$ car les valeurs $N_i$ sont asscociées aux différentes valeurs $x_i$ que peut prendre la variable aléatoire.\n",
    "2. Appliquer le test du $\\chi^2$ à un échantillon quelconque lorsque l'on retient une loi continue, impose de construire $k$ intervalles. Le choix de $k$ étant arbitraire, il est plus simple d'appliquer le test de Kolmogorov-Smirnov car la fonction de répartition de la loi est connue.\n",
    "\n",
    "On peut toutefois réaliser plusieurs tests de $\\chi^2$ avec différentes valeurs de $k$ pour vérifier que ce choix arbitraire n'influence pas le résultat.\n",
    "\n",
    "Les deux tests peuvent également être utilisés de manière complémentaire.\n",
    "\n",
    "[Retour en haut](#Table-des-matières)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test d'indépendance\n",
    "\n",
    "Nous allons maintenant voir comment tester l'indépendance entre deux variables aléatoires.\n",
    "\n",
    "### Test du $\\chi^2$\n",
    "\n",
    "On considère deux variables qualitatives d'une population et on souhaite déterminer s'il existe un lien entre elles (ex: la couleur des yeux et la couleur des cheveux).\n",
    "\n",
    "**L'hypothèse nulle** est que les deux variables $A$ et $B$ **sont indépendantes**. On peut construire un tableau à double entrée qui reprend le nombre de personnes dans chaque catégorie. Par exemple :\n",
    "\n",
    "Cheveux \\ Yeux | Bleus | Marrons\n",
    "---------------|-------|--------\n",
    "**Blonds**     | 26    | 14\n",
    "**Bruns**      | 24    | 36\n",
    "\n",
    "\n",
    "On peut alors comparer les observations $O_{ij}$ (ex: nombre de personnes avec des yeux bleus et des cheveux bruns) aux nombres attendus $E_{ij}$ où $i$ indice les valeurs de $A$ et $j$ celles de $B$. Pour calculer les nombres attendus $E_{ij}$, on utilise le fait que si $A$ et $B$ sont indépendants,\n",
    "$$\n",
    "P(A \\cap B) = P(A) \\cdot P(B).\n",
    "$$\n",
    "On a donc\n",
    "$$\n",
    "E_{ij} = n \\cdot \\dfrac{n_i \\cdot n_j}{n^2} = \\dfrac{n_i \\cdot n_j}{n}.\n",
    "$$\n",
    "\n",
    "On considère\n",
    "\n",
    "$$\n",
    "D = \\sum_{i=1}^{k_A} \\sum_{j=1}^{k_B} \\dfrac{(O_{ij} - E_{ij})^2}{E_{ij}}\n",
    "$$\n",
    "où $k_A$ et $k_B$ représentent respectivement le nombre de valeurs que prennent $A$ et $B$. Lorsque la taille $n$ de notre échantillon tend vers l'infini, $D$ tend vers une loi du $\\chi^2$ à $(k_A - 1) \\cdot (k_B - 1)$ d.d.l. On va donc rejeter l'indépendance des deux variables si $D$ est plus grand que le fractile d'ordre $1-\\alpha$ de la loi du $\\chi^2$ à $(k_A - 1) \\cdot (k_B - 1)$ d.d.l.\n",
    "\n",
    "[Retour en haut](#Table-des-matières)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Démonstration avec python\n",
    "\n",
    "Dans cette section, nous allons voir comment réaliser ces différents tests à l'aide de python.\n",
    "\n",
    "### Test de Kolmogorov-Smirnov.\n",
    "\n",
    "Considérons un échantillon aléatoire de loi parente (normalement inconnue) exponentielle. On va tester si cet échantillon suit bien une loi exponentielle.\n",
    "\n",
    "Comme la loi retenue est continue, le test de KS est moins arbitraire. La loi exponentielle telle que [définie dans numpy](https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.exponential.html#numpy.random.Generator.exponential) dépend d'un paramètre d'échelle $\\beta$. Ce paramètre devra être estimé mais il correspond à la moyenne, on utilisera donc la moyenne empirique comme estimateur. Le test de KS peut se faire via [`scipy.stats.kstest`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kstest.html). Il faut spécifier:\n",
    "* `rvs` : l'échantillon dont on dispose.\n",
    "* `cdf` : la loi de probabilité théorique, sous forme d'une chaîne de caractères et doit correspondre à une des distributions reprises [ici](https://docs.scipy.org/doc/scipy/reference/stats.html#continuous-distributions).\n",
    "* `args` : un tuple qui reprend les valeurs des paramètres de la loi théorique. **Attention, les distributions dans scipy et numpy ne sont pas toujours définies de la même manière**.\n",
    "\n",
    "Dans notre cas,\n",
    "```python\n",
    "scipy.stats.kstest(sample, cdf=\"expon\", args=(0, scale_estimate))\n",
    "```\n",
    "car dans scipy, la distribution exponentielle se nomme `expon` et dépend de deux paramètres (contrairement à celle de numpy), `loc` et `scale`. Pour nous, `loc=0` et `scale` est l'estimateur de $\\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD7CAYAAABzGc+QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAORUlEQVR4nO3dfYxl9V3H8fdHFtJCGwF3uiILXrSUBhuBZiRU1Ai0DVoC/NEQmtqskWQTUytVIkJNTEyMoWpKSTTqBpBNRB5CQQiplc0WbEwq7fL8sEUQWbrrwg4WLNWkdduvf9wz6TDMw925M3PuL7xfyWTuOffM3O88vefcM/fMTVUhSWrPj/Q9gCRpZQy4JDXKgEtSowy4JDXKgEtSowy4JDVqwygbJXkBeB34PnCwqqaTHAvcBgyAF4BLqurVtRlTkjTfoeyBn1NVp1fVdLd8FbCzqk4GdnbLkqR1klFO5On2wKer6pU5654Bfrmq9ic5Dnigqk5Z6v1s3LixBoPBeBNL0lvMQw899EpVTc1fP9IhFKCA+5IU8DdVtQ3YVFX7u+tfAjYt904GgwG7du0adWZJEpBkz0LrRw34L1TVviTvAnYk+cbcK6uqurgvdMNbga0AJ5544iGMLElaykjHwKtqX/f6AHAXcCbwcnfohO71gUXedltVTVfV9NTUm+4BSJJWaNmAJzkqyTtnLwMfBp4E7gG2dJttAe5eqyElSW82yiGUTcBdSWa3//uq+lKSrwO3J7kM2ANcsnZjSpLmWzbgVfU8cNoC6/8LOG8thpIkLc8zMSWpUQZckhplwCWpUQZckhrVTMAHgwFJ1v3FU/8lTapRz8Ts3Z49e+jjCZi7h09K0sRpZg9ckvRGBlySGmXAJalRBlySGmXAJalRBlySGmXAJalRBlySGmXAJalRBlySGmXAJalRBlySGmXAJalRBlySGmXAJalRBlySGmXAJalRBlySGmXAJalRBlySGmXAJalRBlySGmXAJalRBlySGmXAJalRBlySGmXAJalRBlySGjVywJMcluSRJPd2yycleTDJc0luS3LE2o0pSZrvUPbALwd2z1n+LHBtVb0beBW4bDUHkyQtbaSAJ9kMfAS4vlsOcC5wR7fJduDiNZhPkrSIUffAPw9cCfygW/4x4LWqOtgt7wWOX93RJElLWTbgSS4ADlTVQyu5gSRbk+xKsmtmZmYl70KStIBR9sDPBi5M8gJwK8NDJ9cBRyfZ0G2zGdi30BtX1baqmq6q6ampqVUYWZIEIwS8qq6uqs1VNQAuBb5cVR8H7gc+2m22Bbh7zaaUJL3JOI8D/33gd5M8x/CY+A2rM5IkaRQblt/kh6rqAeCB7vLzwJmrP5IkaRSeiSlJjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktSoZQOe5G1JvpbksSRPJfmjbv1JSR5M8lyS25IcsfbjSpJmjbIH/l3g3Ko6DTgdOD/JWcBngWur6t3Aq8BlazalJOlNlg14DX2nWzy8eyngXOCObv124OK1GFCStLCRjoEnOSzJo8ABYAfw78BrVXWw22QvcPyaTChJWtBIAa+q71fV6cBm4EzgvaPeQJKtSXYl2TUzM7OyKSVJb3JIj0KpqteA+4EPAEcn2dBdtRnYt8jbbKuq6aqanpqaGmdWSdIcozwKZSrJ0d3ltwMfAnYzDPlHu822AHev0YySpAVsWH4TjgO2JzmMYfBvr6p7kzwN3Jrkj4FHgBvWcE5J0jzLBryqHgfOWGD98wyPh0uSeuCZmJLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUqGUDnuSEJPcneTrJU0ku79Yfm2RHkme718es/biSpFmj7IEfBK6oqlOBs4BPJjkVuArYWVUnAzu7ZUnSOlk24FW1v6oe7i6/DuwGjgcuArZ3m20HLl6jGSVJCzikY+BJBsAZwIPApqra3131ErBpdUeTJC1l5IAneQfwBeDTVfXtuddVVQG1yNttTbIrya6ZmZmxhn2rGQwGJFn3l8Fg0PeHLmkEG0bZKMnhDON9c1Xd2a1+OclxVbU/yXHAgYXetqq2AdsApqenF4y8FrZnzx6GvxvXV5J1v01Jh26UR6EEuAHYXVWfm3PVPcCW7vIW4O7VH0+StJhR9sDPBj4BPJHk0W7dZ4BrgNuTXAbsAS5ZkwklSQtaNuBV9S/AYvepz1vdcSRJo/JMTElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEaN9P/A3+r8/9iSJpEBH0EfT6oA/uKQtDQPoUhSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDVq2YAnuTHJgSRPzll3bJIdSZ7tXh+ztmNKkuYbZQ/8JuD8eeuuAnZW1cnAzm5ZkrSOlg14VX0F+Na81RcB27vL24GLV3csSdJyVnoMfFNV7e8uvwRsWqV5JEkjGvuPmFVVQC12fZKtSXYl2TUzMzPuzUmSOisN+MtJjgPoXh9YbMOq2lZV01U1PTU1tcKbkyTNt9KA3wNs6S5vAe5enXEkSaMa5WGEtwBfBU5JsjfJZcA1wIeSPAt8sFuWJK2jDcttUFUfW+Sq81Z5FknSIfBMTElqlAGXpEYZcElqlAHXgpL08jIYDPr+0KVmLPtHTL01Dc/PWn9JerldqUXugUtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4Jo7/REsajf/MShOnj3+k5T/RUovcA5ekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwqdPHE0n0+WQSg8HAj7nxj3esJ3RIcj5wHXAYcH1VXbMqU0k96OOJJKC/J5PYs2ePH/M6WauPd8V74EkOA/4S+BXgVOBjSU5drcEkSUsb5xDKmcBzVfV8VX0PuBW4aHXGkiQtZ5yAHw98c87y3m6dJGkdrPmTGifZCmztFr+T5JkVvJuNwCt9HTdb4nY3Aq/0dNvLGWu2NfxcLztXT1/njUnW9Gu5lGU+5jX7Phvzc93k91jPHVnp5+wnF1o5TsD3ASfMWd7crXuDqtoGbBvjdkiyq6qmx3kfa2FS54LJnc25Dt2kzuZch261ZxvnEMrXgZOTnJTkCOBS4J7VGUuStJwV74FX1cEkvwX8E8OHEd5YVU+t2mSSpCWNdQy8qr4IfHGVZlnKWIdg1tCkzgWTO5tzHbpJnc25Dt2qzpa+HsgvSRqPp9JLUqMmOuBJzk/yTJLnklzV9zyzkpyQ5P4kTyd5Ksnlfc80V5LDkjyS5N6+Z5mV5OgkdyT5RpLdST7Q90yzkvxO93V8MsktSd7W0xw3JjmQ5Mk5645NsiPJs93rYyZotj/rvp6PJ7krydGTMNec665IUkk2rvdcS82W5FPd5+2pJH86zm1MbMAn/FT9g8AVVXUqcBbwyQmaDeByYHffQ8xzHfClqnovcBoTMl+S44HfBqar6n0M/yB/aU/j3AScP2/dVcDOqjoZ2Nkt9+Em3jzbDuB9VfWzwL8BV6/3UCw8F0lOAD4MvLjeA81xE/NmS3IOwzPWT6uqnwH+fJwbmNiAM8Gn6lfV/qp6uLv8OsMYTcRZqEk2Ax8Bru97lllJfhT4JeAGgKr6XlW91utQb7QBeHuSDcCRwH/2MURVfQX41rzVFwHbu8vbgYvXc6ZZC81WVfdV1cFu8V8ZngvS+1yda4Ergd7+yLfIbL8JXFNV3+22OTDObUxywJs4VT/JADgDeLDnUWZ9nuE37g96nmOuk4AZ4G+7QzvXJzmq76EAqmofw72gF4H9wH9X1X39TvUGm6pqf3f5JWBTn8Ms4TeAf+x7CIAkFwH7quqxvmdZwHuAX0zyYJJ/TvJz47yzSQ74xEvyDuALwKer6tsTMM8FwIGqeqjvWebZALwf+KuqOgP4H/o7FPAG3THlixj+kvkJ4Kgkv9bvVAur4UPGJu5hY0n+gOFhxZsnYJYjgc8Af9j3LIvYABzL8NDr7wG3Z4xz+yc54COdqt+XJIczjPfNVXVn3/N0zgYuTPICw0NO5yb5u35HAob3nvZW1ey9lDsYBn0SfBD4j6qaqar/A+4Efr7nmeZ6OclxAN3rse5yr7Ykvw5cAHy8JuMxyT/N8JfxY93PwWbg4SQ/3utUP7QXuLOGvsbwnvKK/8g6yQGf2FP1u9+YNwC7q+pzfc8zq6qurqrNVTVg+Pn6clX1vjdZVS8B30xySrfqPODpHkea60XgrCRHdl/X85iQP7B27gG2dJe3AHf3OMsbdE/ociVwYVX9b9/zAFTVE1X1rqoadD8He4H3d9+Dk+AfgHMAkrwHOIIx/iHYxAa8++PI7Kn6u4HbJ+hU/bOBTzDcw320e/nVvoeacJ8Cbk7yOHA68Cf9jjPU3Su4A3gYeILhz0QvZ/IluQX4KnBKkr1JLgOuAT6U5FmG9xZ6edarRWb7C+CdwI7uZ+CvJ2SuibDIbDcCP9U9tPBWYMs491w8E1OSGjWxe+CSpKUZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElq1P8DOa6T75ZdlZsAAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La statistique de test vaut 0.067 et la p-valeur 0.739.\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as sp_st\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed = 42\n",
    "rg = np.random.default_rng(seed)\n",
    "\n",
    "sample = rg.exponential(scale=3, size=100)\n",
    "plt.hist(sample, color=\"k\", fill=False)\n",
    "plt.show()\n",
    "\n",
    "scale_estimate = np.mean(sample)\n",
    "\n",
    "stat, pval = sp_st.kstest(sample, cdf=\"expon\", args=(0, scale_estimate))\n",
    "print(\"La statistique de test vaut %.3f et la p-valeur %.3f.\"% (stat, pval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec cet exemple, on accepte l'hypothèse nulle si on considère une erreur de première espèce de 5% car dans ce cas, $K_n = 0.134$. De manière équivalente, on voit que la p-valeur est supérieure à 5%.\n",
    "\n",
    "### Test d'adéquation du $\\chi^2$\n",
    "\n",
    "Ce test n'est pas disponible dans `scipy`. Cependant, il peut être facilement implémenté pour une distribution théorique particulière."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test d'indépendance du $\\chi^2$\n",
    "\n",
    "Les test d'indépendance du $\\chi^2$ peut se faire avec [`scipy.stats.chi2_contingency`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html). Il faut spécifier `observed`, qui correspond au tableau à double entrée des variables $A$ et $B$. Cette fonction retourne :\n",
    "* la statistique de test;\n",
    "* la p-valeur associée à cette statistique;\n",
    "* le nombre de degrés de liberté de la loi du $\\chi^2$;\n",
    "* le tableau des fréquences théoriques.\n",
    "\n",
    "Par défaut, si le nombre de d.d.l. est égale à 1, `scipy.stats.chi2_contingency` effectue une [correction](https://en.wikipedia.org/wiki/Yates%27s_correction_for_continuity) pour le calcul de la statistique. Cependant, cette correction n'est pas nécessaire si $E_{ij}>5~\\forall i, j$ et on devra alors spécifier l'argument `correction` pour mettre sa valeur à `False`.\n",
    "\n",
    "Illustrons cela avec notre exemple des cheveux et des yeux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La valeur de la statistique est 6.000 et la p-valeur vaut 0.014.\n",
      "Le nombre de d.d.l. est 1.\n",
      "Le tableau est théorique est\n",
      " [[20. 20.]\n",
      " [30. 30.]]\n"
     ]
    }
   ],
   "source": [
    "observed = np.array([[26, 14], [24, 36]])\n",
    "stat, pval, dof, expected = sp_st.chi2_contingency(observed, correction=False)\n",
    "print(\"La valeur de la statistique est %.3f et la p-valeur vaut %.3f.\"% (stat, pval))\n",
    "print(\"Le nombre de d.d.l. est %d.\" % dof)\n",
    "print(\"Le tableau est théorique est\\n\", expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que, pour une erreur de première espèce de 5%, on doit rejeter l'hypothèse nulle car le fractile d'ordre 0.95 de la loi du khi-deux à 1 d.d.l. est 3.841. De manière équivalente, la p-valeur est inférieure à 5%.\n",
    "\n",
    "[Retour en haut](#Table-des-matières)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}