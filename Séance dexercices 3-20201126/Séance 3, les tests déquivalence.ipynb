{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests d'équivalence\n",
    "\n",
    "## Table des matières\n",
    "\n",
    "* [Introduction](#Introduction)\n",
    "* [Exemple introductif, test par intervalle de confiance](#Exemple-introductif,-test-par-intervalle-de-confiance)\n",
    "* [Un peu de vocabulaire](#Un-peu-de-vocabulaire)\n",
    "* [Lois remarquables](#Lois-remarquables)\n",
    "* [Test d'équivalence des variances](#Test-d'équivalence-des-variances)\n",
    "* [Test d'équivalence des moyennes](#Test-d'équivalence-des-moyennes)\n",
    "* [Approche par la p-valeur](#Approche-par-la-p-valeur)\n",
    "* [Remarques importantes](#Remarques-importantes)\n",
    "* [Les tests d'équivalence avec python](#Les-tests-d'équivalence-avec-python)\n",
    "* [Les tests d'équivalence avec R](Les%20tests%20d'équivalence%20avec%20R.ipynb)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Dans cette séance, nous allons voir comment vérifier si deux échantillons proviennent d'une loi normale de même variance ou de même moyenne. Pour cela, nous allons d'abord nous baser sur nos connaissances avec une approche par intervalle de confiance. Nous généraliserons ensuite cette approche pour dériver quelques tests statistiques très utiles pour des populations normales. Finalement, nous verrons comment utiliser ces concepts avec python et R.\n",
    "\n",
    "[Retour en haut](#Table-des-matières)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple introductif, test par intervalle de confiance\n",
    "\n",
    "Considérons deux variables aléatoires $X$ et $Y$ suivant chacune une loi normale, $X\\sim\\mathcal{N}(\\mu_1, \\sigma_1^2)$ et $Y\\sim\\mathcal{N}(\\mu_2, \\sigma_2^2)$. On dispose d'un échantillon de taille $n_1$ pour $X$ et d'un échantillon de taille $n_2$ pour $Y$. On voudrait savoir si ces deux échantillons proviennent d'une loi de même moyenne, c'est-à-dire, $\\mu_1 = \\mu_2$.\n",
    "\n",
    "Comme nous l'avons vu à la séance précédente, un échantillon peut fournir un estimateur pour la moyenne. Cet estimateur étant une variable aléatoire, il fluctue autour de la vraie moyenne. On a ainsi pu construire un intervalle de confiance de niveau $1-\\alpha$ qui avait une probabilité $1-\\alpha$ de contenir la vraie moyenne.\n",
    "\n",
    "Pour résoudre notre problème, on peut résonner de la même façon. Si les deux moyennes sont égales, la variable aléatoire $Z = X - Y$ aura une moyenne nulle. On peut ainsi construire un intervalle de confiance pour la moyenne de $Z$ et regarder s'il contient la valeur $0$. On a, $Z\\sim\\mathcal{N}(\\mu_1 - \\mu_2, \\sigma_1^2 + \\sigma_2^2)$ et a donc pour moyenne empirique $\\overline{X}_{n_1} - \\overline{Y}_{n_2}$. **Si on suppose que les moyennes de $X$ et $Y$ sont les mêmes** alors, la variable aléatoire $\\overline{Z}$ suit une loi normale de moyenne $0$ et d'écart-type $\\sqrt{\\dfrac{\\sigma_1^2}{n_1} + \\dfrac{\\sigma_2^2}{n_2}}$.\n",
    "\n",
    "Pour un niveau de confiance $1-\\alpha$, l'intervalle de la moyenne de $Z$ sera,\n",
    "$$\n",
    "\\Bigg [ \\overline{Z} - \\sqrt{\\dfrac{\\sigma_1^2}{n_1} + \\dfrac{\\sigma_2^2}{n_2}} ~u_{1-\\alpha/2}; \\overline{Z} + \\sqrt{\\dfrac{\\sigma_1^2}{n_1} + \\dfrac{\\sigma_2^2}{n_2}}~u_{1-\\alpha/2} \\Bigg ]\n",
    "$$\n",
    "où $u_{1-\\alpha/2}$ est le fraticle d'ordre $1-\\alpha/2$ de la loi normale centrée réduite.\n",
    "\n",
    "On en conclu que:\n",
    "\n",
    "> Sous l'hypothèse que nos moyennes sont égales, il y a une probabilité $1-\\alpha$ que la moyenne de $X-Y$ soit contenue dans l'intervalle\n",
    "$$\\Bigg [ \\overline{Z} \\pm \\sqrt{\\dfrac{\\sigma_1^2}{n_1} + \\dfrac{\\sigma_2^2}{n_2}} ~u_{1-\\alpha/2}\\Bigg ].$$\n",
    "Si la valeur $0$ ne se trouve pas dans cet intervalle, on rejettera l'hypothèse de départ pour en conclure que les moyennes ne sont pas équivalentes.\n",
    "\n",
    "[Retour en haut](#Table-des-matières)\n",
    "\n",
    "## Un peu de vocabulaire\n",
    "\n",
    "Avec l'exemple précédent, on voit que pour réaliser un test statistique, il faut considérer une hypothèse de départ. Cette hypothèse est celle que l'on pense, *a priori*, être vraie. Dans le cas de l'exemple précédent : «Les deux moyennes sont égales». En statistique, on l'appelle **hypothèse nulle** et on la note $H_0$. L'**hypothèse alternative** est ce que l'on note $H_1$. Dans notre cas : «Les deux moyennes sont différentes». Comme on pense *a priori* que $H_0$ est vraie, on fixe son risque de rejet à tort à un certain niveau $\\alpha$. Ce risque est l'**erreur de première espèce**, il correspond à la probabilité d'obtenir un faux négatif.\n",
    "En effet, dans notre exemple, l'intervalle est construit de telle sorte que la probabilité que $0$ n'y soit pas compris vaut $\\alpha$. L'autre possibilité pour que notre test ne donne par le bon résultat a un risque $\\beta$. Il s'agit de la probabilité d'accepter l'hypothèse nulle alors que celle-ci est fausse (faux positif). On appelle $\\beta$ l'**erreur de deuxième espèce**. En résumé,\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\alpha &= P(\\text{Rejeter} H_0 | H_0 \\text{vraie})\\\\\n",
    "\\beta &= P(\\text{Accepter} H_0 | H_0 \\text{fausse}).\n",
    "\\end{cases}\n",
    "$$\n",
    "Le complémentaire de $\\beta$, $P(\\text{Rejeter} H_0 | H_0 \\text{fausse}) = 1-\\beta$ est la **puissance du test**.\n",
    "\n",
    "|                | $H_0$ vraie | $H_0$ fausse |\n",
    "|----------------|-------------|--------------|\n",
    "| Accepter $H_0$ | 1-$\\alpha$ (Vrai positif)  | $\\beta$  (Faux positif)   |\n",
    "| Rejeter $H_0$ | $\\alpha$ (Faux négatif)   | 1-$\\beta$   (Vrai négatif) |\n",
    "\n",
    "Dans le cas où $H_0$ et $H_1$ sont des hypothèses simples, le théorème de Neyman et Pearson permet d'obtenir le test le plus puissant. Pour rappel, une hypothèse est simple si la loi de probabilité de la variable aléatoire est totalement spécifiée lorsque l'hypothèse se réalise. Par exemple, $X$ suit une loi de probabilité de paramètre $\\theta$ et \n",
    "$$\n",
    "\\begin{cases}\n",
    "H_0 : \\theta = \\theta_0\\\\\n",
    "H_1 : \\theta = \\theta_1.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Dans notre exemple,\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "H_0 : \\mu_1 - \\mu_2 = 0\\\\\n",
    "H_1 : \\mu_1 - \\mu_2 \\neq 0.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Le théorème de Neyman et Pearson ne peut pas s'appliquer car l'hypothèse alternative n'est pas simple. Dans ce type de situation, il n'y a pas de théorème pour obtenir le test le plus puissant mais il existe des méthodes de construction comme la méthode du maximum de vraisemblance.\n",
    "\n",
    "[Retour en haut](#Table-des-matières)\n",
    "\n",
    "## Lois remarquables\n",
    "\n",
    "Pour aller plus loin, nous allons revenir sur quelques lois de probabilité importantes. Notons $U$ une variable aléatoire de loi normale centrée réduite.\n",
    "\n",
    "### Loi du $\\chi^2$\n",
    "\n",
    "Si on somme les carrés de $n$ variables aléatoires $U_i$ indépendantes, le résultat obtenu $Z_n$ suit une loi du $\\chi^2$ à $n$ degrés de liberté.\n",
    "$$\n",
    "Z_n = \\sum_{i=1}^{n} U_i^2 \\sim \\chi^2_n\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as sp_st\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "\n",
    "def plot_chi2(ndof):\n",
    "    plt.close()\n",
    "    xmax = sp_st.chi2.ppf(0.99, ndof)\n",
    "    x = np.linspace(0, xmax, 100)\n",
    "    plt.plot(x, sp_st.chi2.pdf(x, ndof), color=\"k\")\n",
    "    plt.ylabel(\"Densité de probabilité\")\n",
    "    plt.title(rf\"Loi du $\\chi^2$ à {ndof} degrés de liberté\")\n",
    "    plt.show()\n",
    "\n",
    "interact(plot_chi2, ndof=(1, 10, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loi de Student\n",
    "\n",
    "À partir des variables aléatoires indépendantes $U \\sim \\mathcal{N}(0, 1)$ et $Z_n \\sim \\chi^2_n$, on construit la variable $T_n$ qui suit une loi de Student à $n$ degrés de liberté.\n",
    "$$\n",
    "T_n = \\dfrac{U}{\\sqrt{Z_n/n}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_student(ndof):\n",
    "    plt.close()\n",
    "    xmax = sp_st.t.ppf(0.99, ndof)\n",
    "    x = np.linspace(-xmax, xmax, 100)\n",
    "    plt.plot(x, sp_st.t.pdf(x, ndof), color=\"k\")\n",
    "    plt.ylabel(\"Densité de probabilité\")\n",
    "    plt.title(rf\"Loi de Student à {ndof} degrés de liberté\")\n",
    "    plt.show()\n",
    "\n",
    "interact(plot_student, ndof=(1, 10, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loi de Fisher-Snedecor\n",
    "\n",
    "Soient deux variables aléatoires $Z_{n_1} \\sim \\chi^2_{n_1}$ et $Z_{n_2} \\sim \\chi^2_{n_2}$ indépendantes. Alors la varibale aléatoire \n",
    "$$\n",
    "F_{n_1, n_2} = \\dfrac{Z_{n_1}/n_1}{Z_{n_2}/{n_2}}\n",
    "$$\n",
    "suit une loi de Fisher-Snedecor à $n_1, n_2$ degrés de liberté."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fisher(ndof1, ndof2):\n",
    "    plt.close()\n",
    "    xmax = sp_st.f.ppf(0.99, ndof1, ndof2)\n",
    "    x = np.linspace(0, xmax, 100)\n",
    "    plt.plot(x, sp_st.f.pdf(x, ndof1, ndof2), color=\"k\")\n",
    "    plt.ylabel(\"Densité de probabilité\")\n",
    "    plt.title(rf\"Loi de Fisher-Snedecor à {ndof1}, {ndof2} degrés de liberté\")\n",
    "    plt.show()\n",
    "\n",
    "interact(plot_fisher, ndof1=(1, 10, 1), ndof2=(1, 10, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Retour en haut](#Table-des-matières)\n",
    "\n",
    "## Test d'équivalence des variances\n",
    "\n",
    "Considérons deux variables aléatoires $X\\sim\\mathcal{N}(\\mu_X, \\sigma_X^2)$ et $Y\\sim\\mathcal{N}(\\mu_Y, \\sigma_Y^2)$. Supposons que l'on possède un échantillon de taille $n$ pour $X$ et un échantillon de taille $m$ pour $Y$.\n",
    "\n",
    "On pense *a priori* que nos variances sont équivalentes. Si cette hypothèse est vérifiée, $\\sigma_X^2/\\sigma_Y^2 = 1$. Comme on ne connait pas ces deux variances, on construit\n",
    "$$\n",
    "F = \\dfrac{S_X^2}{S_Y^2}\n",
    "$$\n",
    "où $S^2$ désigne l'estimateur sans biais de la variance. $F$ est une variable aléatoire car c'est un ratio de deux variables aléatoires. On peut montrer que\n",
    "$$\n",
    "(n-1)\\dfrac{S_n^2}{\\sigma^2} = \\sum_{i = 1}^{n} \\left(\\dfrac{X_i - \\overline{X}_n}{\\sigma}\\right)^2\n",
    "$$ \n",
    "suit une loi du $\\chi^2$ à $n-1$ degrés de liberté. Intuitivement on le comprend on notant que l'on somme $n$ variables aléatoires de lois normales centréeq réduites mais que seulement $n-1$ sont indépendantes car elles sont liées par\n",
    "$$\n",
    "\\overline{X}_n = \\dfrac{1}{n} \\sum_{i = 1}^{n} X_i.\n",
    "$$\n",
    "\n",
    "Ainsi on voit que l'on peut réécrire $F$ comme,\n",
    "$$\n",
    "\\begin{align}\n",
    "F &= \\dfrac{S_X^2}{S_Y^2} \\cdot \\dfrac{\\sigma^2}{\\sigma^2} \\cdot \\dfrac{(n-1)/(n-1)}{(m-1)/(m-1)}\\\\\n",
    "  &= \\dfrac{((n-1) S_X^2/\\sigma^2)/(n-1)}{((m-1) S_Y^2/\\sigma^2)/(m-1)}.\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$F$ est donc un quotient de variables aléatoires du $\\chi^2$ chacune divisée par leur nombre de degrés de liberté car, par hypothèse, $\\sigma_X^2 = \\sigma_Y^2 = \\sigma^2$. $F$ suit donc une loi de Fisher-Snedecor à $n-1, m-1$ degrés de liberté.\n",
    "\n",
    "On va rejeter l'hypothèse nulle si la valeur que prend $F$ est trop grande ou trop petite. Pour que la probabilité de rejeter à tort l'hypothèse nulle soit de $\\alpha$, il faut que $F$ soit trop petite avec une probabilité $\\alpha/2$ et trop grande avec la même probabilité. Autrement dit, on rejette $H_0$ si $F>f_{n-1, m-1, 1-\\alpha/2}$ ou $F<f_{n-1, m-1, \\alpha/2}$ où $f_{n-1, m-1, 1-\\alpha/2}$ et $f_{n-1, m-1, \\alpha/2}$ correspondent respectivement aux fractiles d'ordre $1-\\alpha/2$ et $\\alpha/2$ de la loi de Fisher-Snedecor à $n-1, m-1$ degrés de liberté.\n",
    "\n",
    "Pour résumé :\n",
    "> $X$ et $Y$ doivent suivrent des lois normales et être indépendantes.\n",
    "$$\n",
    "H_0 : \\sigma_X^2/\\sigma_Y^2 = 1\n",
    "$$\n",
    "Sous l'hypothèse nulle,\n",
    "$$\n",
    "F = \\dfrac{S_X^2}{S_Y^2}\n",
    "$$\n",
    "suit une loi de Fisher-Snedecor à $n-1, m-1$ d.d.l.<br>\n",
    "Dans le cas où\n",
    "$$\n",
    "H_1 : \\sigma_X^2/\\sigma_Y^2 \\neq 1.\n",
    "$$\n",
    "On accepte l'hypothèse nulle si\n",
    "$$\n",
    "f_{n-1, m-1, \\alpha/2} < F < f_{n-1, m-1, 1-\\alpha/2}.\n",
    "$$\n",
    "C'est équivalent à regarder $F < f_{n-1, m-1, 1-\\alpha/2}$ si $F > 1$ ou $F > f_{n-1, m-1, \\alpha/2}$ si $F < 1$.<br>\n",
    "Dans le cas où $S_X^2 > S_Y^2$ et\n",
    "$$\n",
    "H_1 : \\sigma_X^2/\\sigma_Y^2 > 1\n",
    "$$\n",
    "on accepte $H_0$ si $F < f_{n-1, m-1, 1-\\alpha}$.<br>\n",
    "Dans le cas $S_X^2 < S_Y^2$ et\n",
    "$$\n",
    "H_1 : \\sigma_X^2/\\sigma_Y^2 < 1\n",
    "$$\n",
    "on accepte $H_0$ si $F > f_{n-1, m-1, \\alpha}$.\n",
    "\n",
    "### Évolution de la zone de rejet en fonction de $\\alpha$\n",
    "\n",
    "On peut représenter la zone de rejet du test sous l'hypothèse nulle, en fonction de $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisher_test_reject_area(n, m, alpha):\n",
    "    plt.close()\n",
    "    xmax = sp_st.f.ppf(0.999, n-1, m-1)\n",
    "    x = np.linspace(0, xmax, 200)\n",
    "    thresholds = np.array([sp_st.f.ppf(alpha/2, n-1, m-1), sp_st.f.ppf(1-alpha/2, n-1, m-1)])\n",
    "    xinf = x[x<thresholds[0]]\n",
    "    xsup = x[x>thresholds[1]]\n",
    "\n",
    "    plt.plot(x, sp_st.f.pdf(x, n-1, m-1), color=\"k\")\n",
    "    plt.fill_between(xinf, sp_st.f.pdf(xinf, n-1, m-1), color=\"r\", alpha=0.2)\n",
    "    plt.axvline(thresholds[0], color=\"r\")\n",
    "    plt.fill_between(xsup, sp_st.f.pdf(xsup, n-1, m-1), color=\"r\", alpha=0.2)\n",
    "    plt.axvline(thresholds[1], color=\"r\")\n",
    "    plt.ylabel(\"Densité de probabilité\")\n",
    "    plt.title(rf\"Zone de rejet (rouge) du test de Fisher\")\n",
    "    plt.show()\n",
    "\n",
    "interact_manual(fisher_test_reject_area, n=(4, 20, 1), m=(4, 20, 1), alpha=(0.01, 0.99, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considérons un petit exemple. On va générer deux échantillons aléatoires normaux avec même variance théorique. On va ensuite tester l'hypothèse nulle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "rg = np.random.default_rng(seed)\n",
    "sample1 = rg.normal(loc=0, scale=1, size=16)\n",
    "sample2 = rg.normal(loc=1, scale=1, size=21)\n",
    "plt.hist(sample1, alpha=0.5)\n",
    "plt.hist(sample2, alpha=0.5)\n",
    "plt.title(\"Histogrammes des deux échantillons\")\n",
    "plt.plot()\n",
    "\n",
    "def f_test(sample1, sample2, alpha=0.05):\n",
    "    var1 = np.var(sample1, ddof=1)\n",
    "    var2 = np.var(sample2, ddof=1)\n",
    "\n",
    "    n = sample1.size\n",
    "    m = sample2.size\n",
    "\n",
    "    stat = var1/var2\n",
    "    thresholds = np.array([sp_st.f.ppf(alpha/2, n-1, m-1), sp_st.f.ppf(1-alpha/2, n-1, m-1)])\n",
    "    if (thresholds[0] < stat) and (stat < thresholds[1]):\n",
    "        return \"On accepte H0\", stat, thresholds\n",
    "    else:\n",
    "        return \"On accepte H1\", stat, thresholds\n",
    "\n",
    "ans, stat, thresholds = f_test(sample1, sample2)\n",
    "print(\"La réponse est '%s' car F vaut %.2f et la zone d'acceptation est [%.2f %.2f]\" % (ans, stat, *thresholds,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Retour en haut](#Table-des-matières)\n",
    "\n",
    "## Test d'équivalence des moyennes\n",
    "\n",
    "Comme dans notre exemple introductif, on souhaite comparer deux moyennes. On considère deux variables $X\\sim\\mathcal{N}(\\mu_X, \\sigma_X^2)$ et $Y\\sim\\mathcal{N}(\\mu_Y, \\sigma_Y^2)$ dont on a un échantillon de taille $n$ et $m$ respectivement. On pense, *a priori*, que les moyennes sont égales.\n",
    "\n",
    "\n",
    "### Test Z\n",
    "\n",
    "Considérons que l'on connait la variance des deux lois. On peut alors construire une variable aléatoire qui suit une loi normale centrée réduite. En effet, sous l'hypothèse nulle, $\\overline{X}-\\overline{Y}$ suit une loi normale centrée de variance $\\sigma_X^2/n + \\sigma_Y^2/m$. Ainsi la variable aléatoire\n",
    "$$\n",
    "Z = \\dfrac{ \\overline{X} - \\overline{Y} }{ \\sqrt{\\dfrac{\\sigma_X^2}{n} + \\dfrac{\\sigma_Y^2}{m}}}\n",
    "$$\n",
    "suit une loi normale centrée réduite sous l'hypothèse nulle. On rejettera $H_0$ si $Z$ est soit «trop grand», soit «trop petit». Pour fixer ces deux bornes, on utilise le fait que l'erreur de première espèce vaut $\\alpha$. Il y a donc une probabilité $\\alpha/2$ pour chacune des deux situations. La loi normale étant symétrique, on rejette $H_0$ si $|Z|>u_{1-\\alpha/2}$ ou $u_{1-\\alpha/2}$ est le fractile d'ordre $1-\\alpha/2$ de la loi normale centrée réduite.\n",
    "\n",
    "Cette approche est équivalente à celle de l'exemple introductif. En effet, ici on a $P(|Z|<u_{1-\\alpha/2}) = 1-\\alpha$ ce qui implique qu'un intervalle de confiance pour la différence des moyennes $\\mu_X-\\mu_Y$ est\n",
    "$$\n",
    "\\Bigg [ \\overline{X} - \\overline{Y} \\pm \\sqrt{\\dfrac{\\sigma_X^2}{n} + \\dfrac{\\sigma_Y^2}{m}} ~u_{1-\\alpha/2}\\Bigg ]\n",
    "$$\n",
    "si on se rapporte à ce que l'on a fait à la dernière séance.\n",
    "\n",
    "### Test t de Student et test t de Welch\n",
    "\n",
    "* Si les variances sont équivalentes, $\\sigma_X^2=\\sigma_Y^2=\\sigma^2$.\n",
    "\n",
    "    Dans ce cas, on estime la variance de $X$ et $Y$ via\n",
    "    $$\n",
    "    S_p^2 = \\dfrac{(n-1) S_X^2 + (m-1) S_Y^2}{n+m-2},\n",
    "    $$\n",
    "    moyenne pondérée des deux variances empiriques. $S_p^2$ est un estimateur sans biais de la variance théoriques ($E(S_p^2) = \\sigma^2$). On appelle $S_p^2$, la «variance regroupée» (pooled variance).\n",
    "\n",
    "    La variance de $\\overline{X} - \\overline{Y}$ est ainsi estimée par $S_p^2/n + S_p^2/m$. On construit\n",
    "    $$\n",
    "    T = \\dfrac{\\overline{X} - \\overline{Y}}{S_p \\sqrt{\\dfrac{1}{n} + \\dfrac{1}{m}}}\n",
    "    $$\n",
    "    et on remarque que,\n",
    "    $$\n",
    "    T = \\dfrac{\\overline{X} - \\overline{Y}}{\\sigma \\sqrt{\\dfrac{1}{n} + \\dfrac{1}{m}}} \\dfrac{\\sigma}{S_p}.\n",
    "    $$\n",
    "    Comme $S_X^2 \\sim \\sigma^2 \\chi^2_{n-1}/(n-1)$ et $S_Y^2 \\sim \\sigma^2 \\chi^2_{m-1}/(m-1)$, $S_p^2 \\sim \\sigma^2 \\chi^2_{n+m-2}/(n+m-2)$. Ainsi,\n",
    "    $$\n",
    "    T \\sim \\dfrac{\\mathcal{N}(0, 1)}{\\sqrt{\\chi^2_{n+m-2}/(n+m-2)}}\n",
    "    $$\n",
    "    et suit donc une loi de Student à $n+m-2$ d.d.l.\n",
    "    \n",
    "    Comme la loi de Student est symmétrique, on va rejeter $H_0$ si $|T|>t_{m+n-2, 1-\\alpha/2}$ où $t_{m+n-2, 1-\\alpha/2}$ est le fractile d'ordre $1-\\alpha/2$ de la loi du Student à $n+m-2$ d.d.l.\n",
    "    \n",
    "    Son équivalent avec l'intervalle de confiance est donc : on rejette l'hypothèse nulle si $0$ n'est pas compris dans l'intervalle\n",
    "    $$\n",
    "    \\Bigg [ \\overline{X}-\\overline{Y} \\pm S_p \\sqrt{\\dfrac{1}{n} + \\dfrac{1}{m}} ~t_{n+m-2,1-\\alpha/2}\\Bigg ].\n",
    "    $$\n",
    "\n",
    "* Si les variances ne sont pas équivalentes, $\\sigma_X^2 \\neq \\sigma_Y^2$, on construit\n",
    "    $$\n",
    "    T = \\dfrac{\\overline{X} - \\overline{Y}}{\\sqrt{\\dfrac{S_X^2}{n} + \\dfrac{S_Y^2}{m}}}.\n",
    "    $$\n",
    "    La distribution de $T$ peut être **approximée** par une loi de student à $\\nu$ d.d.l. où, \n",
    "    $$\n",
    "    \\nu = \\dfrac{\\left(\\frac{s_X^2}{n} + \\frac{s_Y^2}{m}\\right)^2}{\\frac{\\left(s_X^2/n\\right)^2}{n-1} + \\frac{\\left(s_Y^2/m\\right)^2}{m-1}}.\n",
    "    $$\n",
    "    \n",
    "    On rejette $H_0$ si $|T| > t_{\\nu, 1-\\alpha/2}$ ou si $0$ n'est pas dans l'intervalle\n",
    "     $$\n",
    "     \\Bigg [ \\overline{X}-\\overline{Y} \\pm \\sqrt{\\dfrac{S_X^2}{n} + \\dfrac{S_Y^2}{m}} ~t_{\\nu,1-\\alpha/2}\\Bigg ]\n",
    "     $$\n",
    "     où $t_{\\nu,1-\\alpha/2}$ est le fractile d'ordre $1-\\alpha/2$ de la loi de Student à $\\nu$ d.d.l.\n",
    "\n",
    "Pour résumer :\n",
    "> $X$ et $Y$ doivent être deux variables aléatoires indépendantes et de loi normale.\n",
    "$$\n",
    "H_0 : \\mu_X - \\mu_Y = 0\n",
    "$$\n",
    "**Dans le cas où $\\sigma^2_X$ et $\\sigma^2_Y$ sont connues**, on utilise le test $Z$. Sous l'hypothèse nulle,\n",
    "$$\n",
    "Z = \\dfrac{ \\overline{X} - \\overline{Y} }{ \\sqrt{\\dfrac{\\sigma_X^2}{n} + \\dfrac{\\sigma_Y^2}{m}}}\n",
    "$$\n",
    "suit une loi normale centrée réduite.<br>\n",
    "Si\n",
    "$$\n",
    "H_1 : \\mu_X - \\mu_Y \\neq 0,\n",
    "$$\n",
    "alors on rejette $H_0$ si $|Z| > u_{1-\\alpha/2}$.<br>\n",
    "Si $$ \\overline{X} > \\overline{Y}$$ et\n",
    "$$\n",
    "H_1 : \\mu_X - \\mu_Y > 0,\n",
    "$$\n",
    "alors on rejette $H_0$ si $Z>u_{1-\\alpha}$.<br>\n",
    "Si $$ \\overline{X} < \\overline{Y}$$ et\n",
    "$$\n",
    "H_1 : \\mu_X - \\mu_Y < 0,\n",
    "$$\n",
    "alors on rejette $H_0$ si $Z<u_{\\alpha}$.<br><br>\n",
    "**Si $\\sigma_X^2$ et $\\sigma^2_Y$ ne sont pas connues mais sont équivalentes** (test de Fisher ok), alors on utilise le test t de Student. Sous l'hypothèse nulle,\n",
    "$$\n",
    "T = \\dfrac{\\overline{X} - \\overline{Y}}{S_p \\sqrt{\\dfrac{1}{n} + \\dfrac{1}{m}}}\n",
    "$$\n",
    "suit une loi de Student à $n+m-2$ degrés de liberté.<br>\n",
    "Si\n",
    "$$\n",
    "H_1 : \\mu_X - \\mu_Y \\neq 0,\n",
    "$$\n",
    "alors on rejette $H_0$ si $|T| > t_{n+m-2, 1-\\alpha/2}$.<br>\n",
    "Si $$ \\overline{X} > \\overline{Y}$$ et\n",
    "$$\n",
    "H_1 : \\mu_X - \\mu_Y > 0,\n",
    "$$\n",
    "alors on rejette $H_0$ si $T>t_{n+m-2, 1-\\alpha}$.<br>\n",
    "Si $$ \\overline{X} < \\overline{Y}$$ et\n",
    "$$\n",
    "H_1 : \\mu_X - \\mu_Y < 0,\n",
    "$$\n",
    "alors on rejette $H_0$ si $T<t_{n+m-2, \\alpha}$.<br><br>\n",
    "**Si $\\sigma_X^2$ et $\\sigma^2_Y$ ne sont pas connues et ne sont équivalentes** (test de Fisher pas ok), alors on utilise le t de Welch. Sous l'hypothèse nulle,\n",
    "$$\n",
    "T = \\dfrac{\\overline{X} - \\overline{Y}}{\\sqrt{\\dfrac{S_X^2}{n} + \\dfrac{S_Y^2}{m}}}.\n",
    "$$\n",
    "suit approximativement une loi de Student à \n",
    "$$\n",
    "\\nu = \\dfrac{\\left(\\frac{s_X^2}{n} + \\frac{s_Y^2}{m}\\right)^2}{\\frac{\\left(s_X^2/n\\right)^2}{n-1} + \\frac{\\left(s_Y^2/m\\right)^2}{m-1}}.\n",
    "$$\n",
    "degrés de liberté.<br>\n",
    "Si\n",
    "$$\n",
    "H_1 : \\mu_X - \\mu_Y \\neq 0,\n",
    "$$\n",
    "alors on rejette $H_0$ si $|T| > t_{\\nu, 1-\\alpha/2}$.<br>\n",
    "Si $$ \\overline{X} > \\overline{Y}$$ et\n",
    "$$\n",
    "H_1 : \\mu_X - \\mu_Y > 0,\n",
    "$$\n",
    "alors on rejette $H_0$ si $T>t_{\\nu, 1-\\alpha}$.<br>\n",
    "Si $$ \\overline{X} < \\overline{Y}$$ et\n",
    "$$\n",
    "H_1 : \\mu_X - \\mu_Y < 0,\n",
    "$$\n",
    "alors on rejette $H_0$ si $T<t_{\\nu, \\alpha}$.<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on le voit, lorsque l'on effectue un test d'hypothèse, on construit une variable aléatoire. Cette variable aléatoire est ce que l'on appelle **une statistique**. Cette statistique est construite de manière à ce que, **sous l'hypothèse nulle**, elle suive une loi connue. On compare ainsi la valeur que prend la statistique avec nos échantillons à une zone d'acceptation définie par les fractiles de cette loi.\n",
    "\n",
    "[Retour en haut](#Table-des-matières)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approche par la p-valeur\n",
    "\n",
    "Dans les différents tests que nous avons présentés, on a toujours comparé la valeur de la statistique de test à une région d'acceptation. Toutefois, lorsque l'on a calculé cette statistique, on peut s'intéresser à la probabilité d'obtenir une valeur au moins égale à celle que l'on a. Par exemple, pour le test Z, on pourrait regarder la probabilité\n",
    "$$\n",
    "p = P(Z < -|z|~\\text{alors que}~H_0~\\text{vraie}) + P(Z > |z|~\\text{alors que}~H_0~\\text{vraie})\n",
    "$$\n",
    "où $z$ est la valeur que prend la statistique avec nos échantillons. Si cette probabilité est plus petite que $\\alpha$, cela veut dire que $|z|$ est plus grand que le fractile d'ordre $1-\\alpha/2$ de la loi normale centrée réduite, autrement dit, on doit rejeter $H_0$.\n",
    "\n",
    "La probabilité $p$ d'obtenir une valeur au moins aussi extrème que celle observée pour la statistique, sous l'hypothèse nulle, est ce que l'on appelle la p-valeur.\n",
    "> On rejette $H_0$ si $p < \\alpha$. <br>\n",
    "    On accepte $H_0$ si $p > \\alpha$.\n",
    "\n",
    "Généralement, les outils informatiques permettant d'effectuer des tests statistiques donnent la valeur de la statistique de test ainsi que la p-valeur qui lui est associée.\n",
    "\n",
    "[Retour en haut](#Table-des-matières)\n",
    "\n",
    "## Remarques importantes\n",
    "\n",
    "Comme nous le voyons, la mise en place des tests d'hypothèses est élaborée et rigoureuse mais l'utilisation de ces tests est extrêmement simple. Il suffit de comparer une valeur à un seuil pour en tirer une conclusion. Cette facilité d'utilisation constitue finalement un danger. En effet, la simplicité permet à n'importe d'utiliser n'importe quel test pour vérifier n'importe quoi. Il est donc bon d'apporter quelques mises en garde.\n",
    "\n",
    "1. L'erreur de première espèce $\\alpha$ ne correspond pas à la probabilité de vous tromper lorsque vous faites le test. En effet, vous vous trompez si vous rejeter $H_0$ alors que $H_0$ est vraie (probabilité $\\alpha$) mais vous vous trompez également si vous accepter $H_0$ alors que $H_0$ est fausse (probabilité $\\beta$).\n",
    "2. Vouloir réduire $\\alpha$ revient généralement à augmenter $\\beta$. Le seul moyen de réduire les deux est d'augmenter la taille des échantillons.\n",
    "3. La p-valeur ne mesure pas la probabilité que $H_0$ soit vraie. La probabilité que $H_0$ soit vraie étant donnée la valeur que prend la statistique de test $z$ est\n",
    "$$\n",
    "P(H_0 | z) = \\dfrac{P(z | H_0) P(H_0)}{P(z)}\n",
    "$$\n",
    "et la p-valeur est reliée à $P(z | H_0)$.\n",
    "4. Il est capital que toutes les hypothèses sur les données soient vérifiées avant d'effectuer le test associé.\n",
    "5. Comme la puissance du test est reliée à la taille des échantillons, tirer des conclusions sur de petits échantillons est une mauvaise idée. De plus, le test s'appuie sur nos connaissances *a priori*. Ainsi, si on se trompe et que les deux moyennes sont en réalité différentes, alors, en considérant $\\alpha$ petit, le test ne va pas fonctionner.\n",
    "\n",
    "Pour voir comment tout cela se passe, on peut procéder à une simulation. On considère deux cas :\n",
    "1. On a deux échantillons qui suivent une loi normale de même moyenne, pour un test de student, l'hypothèse nulle est vraie.\n",
    "2. On a deux échantillons qui suivent une loi normale mais la moyenne est différente (différence d'un écart-type). Pour un test de Student l'hypothèse nulle est fausse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_err(alpha, sample_size, plot=False):\n",
    "    # On réalise 1000 test\n",
    "    ntest = 1000\n",
    "\n",
    "    # On va garder en mémoire les p-valeurs et les statistiques\n",
    "    p_values1  = np.zeros(ntest)\n",
    "    diff_mean1 = np.zeros(ntest)\n",
    "    p_values2  = np.zeros(ntest)\n",
    "    diff_mean2 = np.zeros(ntest)\n",
    "\n",
    "    for i in range(ntest):\n",
    "        # On construit les échantillons\n",
    "        sample1 = rg.normal(loc=0, scale=1, size=sample_size)\n",
    "        sample2 = rg.normal(loc=0, scale=1, size=sample_size)\n",
    "        sample3 = rg.normal(loc=1, scale=1, size=sample_size)\n",
    "\n",
    "        # On réalise le test de Student\n",
    "        stat1, pval1 = sp_st.ttest_ind(sample1, sample2)\n",
    "        stat2, pval2 = sp_st.ttest_ind(sample1, sample3)\n",
    "\n",
    "        p_values1[i] = pval1\n",
    "        diff_mean1[i] = stat1\n",
    "        p_values2[i] = pval2\n",
    "        diff_mean2[i] = stat2\n",
    "\n",
    "    # On calcule l'erreur de première espèce pour le premier test\n",
    "    err_type1 = 100*(1-len(np.where(p_values1>alpha)[0])/ntest)\n",
    "    # On calcule l'erreur de deuxième espèce pour le second test\n",
    "    err_type2 = 100*len(np.where(p_values2>alpha)[0])/ntest\n",
    "    print(f\"L'hypothèse nulle est vraie, on la rejette dans %.2f%% des cas (erreur de type 1)\" % err_type1)\n",
    "    print(f\"L'hypothèse nulle est fausse, on l'accepte dans %.2f%% des cas (erreur de type 2)\" % err_type2)\n",
    "    if plot:\n",
    "        plt.figure(1)\n",
    "        plt.subplot(121)\n",
    "        plt.hist(diff_mean1, fill=False)\n",
    "        plt.ylabel(\"Distribution de la statistique\")\n",
    "        plt.subplot(122)\n",
    "        plt.hist(p_values1, fill=False)\n",
    "        plt.axvline(alpha, color=\"r\")\n",
    "        plt.ylabel(\"Distribution de la p-valeur\")\n",
    "        plt.suptitle(\"Hypothèse nulle vraie\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.figure(2)\n",
    "        plt.subplot(121)\n",
    "        plt.hist(diff_mean2, fill=False)\n",
    "        plt.ylabel(\"Distribution de la statistique\")\n",
    "        plt.subplot(122)\n",
    "        plt.hist(p_values2, fill=False)\n",
    "        plt.axvline(alpha, color=\"r\")\n",
    "        plt.ylabel(\"Distribution de la p-valeur\")\n",
    "        plt.suptitle(\"Hypothèse nulle fausse\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "interact_manual(show_err, alpha=(0.01, 0.99, 0.01), sample_size=(4, 200, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit ainsi clairement que si on prend $\\alpha$ très petit alors que l'hypothèse nulle est fausse, on risque de l'accepter quand même régulièrement. Cela est dû au fait que notre test n'est pas puissant. Le seul moyen pour réduire ce risque est d'augmenter la taille de notre échantillon.\n",
    "\n",
    "On considèrera $\\alpha$ petit si rejeter $H_0$ alors que $H_0$ est vraie a de grosses conséquences.\n",
    "\n",
    "[Retour en haut](#Table-des-matières)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les tests d'équivalence avec python\n",
    "\n",
    "Il est possible d'utiliser python pour effectuer des tests statistiques. Toutefois, le test de Fisher et le test Z ne se trouve pas dans `scipy`.\n",
    "\n",
    "Pour réaliser un test de Student, on utilise [`scipy.stats.ttest_ind`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html). Il faut spécifier les deux échantillons. Dans le cas où les variances ne sont pas équivalentes, on devra spécifier :\n",
    "```python\n",
    "equal_var=False\n",
    "```\n",
    "Ce test retourne la statistique et la p-valeur associée. Souvent, les méthodes numériques proposent un argument nommé `alternative` qui correspond à l'hypothèse alternative. Il peut prendre trois valeurs:\n",
    "* «two-sided» : $\\sigma_X^2/\\sigma_Y^2 \\neq 1$ ou $\\mu_1 - \\mu_2 \\neq 0$\n",
    "* «greater» : $\\sigma_X^2/\\sigma_Y^2 > 1$ ou $\\mu_1 - \\mu_2 > 0$\n",
    "* «less» : $\\sigma_X^2/\\sigma_Y^2 < 1$ ou $\\mu_1 - \\mu_2 < 0$\n",
    "cet argument influe sur le calcul de la p-valeur. Par exemple, pour un test de student, dans le cas «two-sided» on calculera\n",
    "$$\n",
    "p = P(T < -|t|) + P(T > |t|).\n",
    "$$\n",
    "Alors que pour «greater» on aura uniquement\n",
    "$$\n",
    "p = P(T > t)\n",
    "$$\n",
    "et pour «less»\n",
    "$$\n",
    "p = P(T < t).\n",
    "$$\n",
    "\n",
    "Dans le fichier `mstats.py` se trouvent les différents tests de cette séance. Nous pouvons l'importer et comparer les résultats au test de Student de scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import mstats\n",
    "\n",
    "sample1 = rg.normal(loc=0, scale=1, size=50)\n",
    "sample2 = rg.normal(loc=0, scale=1, size=50)\n",
    "\n",
    "print(\"Dans le cas ou les variances sont identiques:\")\n",
    "print(\"Notre test de Student donne une statistique de %.3f et une pvalue de %.4f.\" % mstats.ttest(sample1, sample2))\n",
    "print(\"Le test de Student de scipy donne une statistique de %.3f et une pvalue de %.4f.\" % sp_st.ttest_ind(sample1, sample2))\n",
    "\n",
    "print(\"\\nTest de Fisher : statistique=%.3f, p-valeur=%.4f\" % mstats.ftest(sample1, sample2))\n",
    "print(\"Test Z : statistique=%.3f, p-valeur=%.4f\" % mstats.ztest(sample1, sample2, 1, 1))\n",
    "\n",
    "sample1 = rg.normal(loc=0, scale=1, size=50)\n",
    "sample2 = rg.normal(loc=0, scale=3, size=50)\n",
    "\n",
    "print(\"\\nDans le cas ou les variances sont différentes:\")\n",
    "print(\"Notre test de Student donne une statistique de %.3f et une pvalue de %.4f.\" % mstats.ttest(sample1, sample2, equal_var=False))\n",
    "print(\"Le test de Student de scipy donne une statistique de %.3f et une pvalue de %.4f.\" % sp_st.ttest_ind(sample1, sample2, equal_var=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme attendu, les deux tests fonctionnent de la même façon. Pour obtenir de l'aide sur l'utilisation des fonctions de `mstats`, il suffit d'utiliser la fonction `help` de python. Par exemple\n",
    "```python\n",
    "help(mstats.ttest)\n",
    "```\n",
    "permet d'obtenir la documentation pour cette fonction.\n",
    "\n",
    "[Retour en haut](#Table-des-matières)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
